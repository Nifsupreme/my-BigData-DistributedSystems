{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.135 seconds\n",
      "OK\n",
      "posts\n",
      "users\n",
      "Time taken: 0.506 seconds, Fetched: 2 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive --database stackoverflow_ -e 'show tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting describe.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile describe.hql\n",
    "USE stackoverflow_;\n",
    "DESCRIBE posts;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.24 seconds\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "post_type_id        \ttinyint             \t                    \n",
      "date                \tstring              \t                    \n",
      "owner_user_id       \tint                 \t                    \n",
      "parent_id           \tint                 \t                    \n",
      "score               \tint                 \t                    \n",
      "favorite_count      \tint                 \t                    \n",
      "tags                \tarray<string>       \t                    \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "\t \t \n",
      "# Partition Information\t \t \n",
      "# col_name            \tdata_type           \tcomment             \n",
      "\t \t \n",
      "year                \tstring              \t                    \n",
      "month               \tstring              \t                    \n",
      "Time taken: 1.353 seconds, Fetched: 16 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f describe.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting post.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile post.hql\n",
    "USE stackoverflow_;\n",
    "\n",
    "SELECT *\n",
    "FROM \n",
    "    posts\n",
    "WHERE\n",
    "    tags IS NOT NULL AND\n",
    "    year IS NOT NULL AND\n",
    "    month IS NOT NULL\n",
    "LIMIT 10\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.153 seconds\n",
      "OK\n",
      "4004\t1\t2008-08-06T21:18:47.357\t525\tNULL\t31\t16\t[\".net\",\"authentication\",\"encryption\",\"ssl\"]\t2008\t2008-08\n",
      "7237\t1\t2008-08-10T16:46:12.640\t799\tNULL\t10\t2\t[\"sql-server\",\"database\"]\t2008\t2008-08\n",
      "8472\t1\t2008-08-12T04:59:35.017\t1\tNULL\t320\t323\t[\"security\",\"language-agnostic\",\"captcha\"]\t2008\t2008-08\n",
      "9303\t1\t2008-08-12T23:04:10.770\t889\tNULL\t12\t1\t[\"c#\",\"regex\",\"perl\"]\t2008\t2008-08\n",
      "9355\t1\t2008-08-13T00:35:50.977\t234\tNULL\t15\t5\t[\"windows\",\"explorer\",\"windows-shell\"]\t2008\t2008-08\n",
      "9831\t1\t2008-08-13T13:49:51.963\t1491425\tNULL\t3\tNULL\t[\"javascript\",\"drag-and-drop\",\"mootools\"]\t2008\t2008-08\n",
      "10260\t1\t2008-08-13T19:18:07.667\t203\tNULL\t6\tNULL\t[\"asp.net\"]\t2008\t2008-08\n",
      "10810\t1\t2008-08-14T08:38:24.760\t966\tNULL\t3\t1\t[\"c#\",\"winforms\",\"authorization\",\"adam\",\"azman\"]\t2008\t2008-08\n",
      "12330\t1\t2008-08-15T15:06:31.873\tNULL\tNULL\t6\t1\t[\"vbscript\",\"wmi\"]\t2008\t2008-08\n",
      "12656\t1\t2008-08-15T19:50:52.517\t1344\tNULL\t5\t9\t[\"php\",\"mysql\",\"orm\",\"mysqli\"]\t2008\t2008-08\n",
      "Time taken: 3.655 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f post.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting describe.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile describe.hql\n",
    "USE stackoverflow_;\n",
    "DESCRIBE users;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.224 seconds\n",
      "OK\n",
      "id                  \tint                 \t                    \n",
      "reputation          \tint                 \t                    \n",
      "creation_date       \tstring              \t                    \n",
      "display_name        \tstring              \t                    \n",
      "location            \tstring              \t                    \n",
      "views               \tint                 \t                    \n",
      "up_votes            \tint                 \t                    \n",
      "down_votes          \tint                 \t                    \n",
      "age                 \tint                 \t                    \n",
      "account_id          \tint                 \t                    \n",
      "Time taken: 1.257 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f describe.hql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting user.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile user.hql\n",
    "USE stackoverflow_;\n",
    "\n",
    "SELECT *\n",
    "FROM \n",
    "    users\n",
    "WHERE\n",
    "    creation_date IS NOT NULL AND\n",
    "    display_name IS NOT NULL AND\n",
    "    location IS NOT NULL\n",
    "LIMIT 10\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.183 seconds\n",
      "OK\n",
      "37\t4146\t2008-08-01T12:44:00.723\tWally Lawless\tGeorgetown, Canada\t654\t256\t18\t35\t28\n",
      "169\t4825\t2008-08-02T22:51:03.507\tArnold Zokas\tLondon, United Kingdom\t585\t1956\t14\tNULL\t138\n",
      "194\t15481\t2008-08-03T10:56:49.987\tAdam Haile\tUnited States\t1973\t217\t18\t33\t157\n",
      "338\t37578\t2008-08-04T18:34:44.117\tFrank Krueger\tUnited States\t3941\t2411\t93\t36\t272\n",
      "480\t276\t2008-08-06T08:40:05.797\tmdy\tAsia\t79\t49\t0\t28\t381\n",
      "756\t2358\t2008-08-08T15:31:50.013\tSimon Gillbee\tPearland, TX\t478\t352\t25\t45\t587\n",
      "923\t58\t2008-08-10T14:25:39.540\tAnotherHowie\tUnited Kingdom\t32\t2\t0\t45\t706\n",
      "1097\t8036\t2008-08-12T11:40:09.933\tGeoff\tStow, OH\t527\t473\t30\t46\t838\n",
      "1462\t2011\t2008-08-15T17:26:18.470\tcrono\tGermany\t119\t73\t1\t35\t1101\n",
      "1539\t2476\t2008-08-16T13:31:36.823\tRyan P\tUnited States\t233\t72\t9\t33\t1158\n",
      "Time taken: 2.447 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "! hive -f user.hql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hive assignment. Task2\n",
    "Compare most popular tags in year 2016 with tags in 2009. Tag popularity is the number of questions (post_type_id=1) with this tag. Output top 10 tags in format:\n",
    "```\n",
    "tag <tab> rank in 2016 <tab> rank in 2009 <tab> tag popularity in 2016 <tab> tag popularity in 2009\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "DROP TABLE IF EXISTS pop_2016;\n",
    "CREATE TABLE IF NOT EXISTS\n",
    "    pop_2016 AS\n",
    "SELECT\n",
    "    year, tag, count(tag) AS popularity\n",
    "FROM\n",
    "    posts\n",
    "LATERAL VIEW\n",
    "    explode(tags) posts AS tag\n",
    "WHERE\n",
    "    year = 2016 AND\n",
    "    post_type_id=1\n",
    "GROUP BY\n",
    "    year, tag\n",
    "ORDER BY\n",
    "    popularity DESC\n",
    ";\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS pop_2009;\n",
    "CREATE TABLE IF NOT EXISTS\n",
    "    pop_2009 AS\n",
    "SELECT\n",
    "    year, tag, count(tag) AS popularity\n",
    "FROM\n",
    "    posts\n",
    "LATERAL VIEW\n",
    "    explode(tags) posts AS tag\n",
    "WHERE\n",
    "    year = 2009 AND\n",
    "    post_type_id=1\n",
    "GROUP BY\n",
    "    year, tag\n",
    "ORDER BY\n",
    "    popularity DESC\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql -a\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS rank_2016;\n",
    "CREATE TABLE IF NOT EXISTS\n",
    "    rank_2016 AS\n",
    "SELECT\n",
    "    tag, popularity, rank() OVER w AS rank\n",
    "FROM\n",
    "    pop_2016\n",
    "WINDOW w AS (PARTITION BY year ORDER BY popularity DESC)\n",
    ";\n",
    "\n",
    "\n",
    "DROP TABLE IF EXISTS rank_2009;\n",
    "CREATE TABLE IF NOT EXISTS\n",
    "    rank_2009 AS\n",
    "SELECT\n",
    "    tag, popularity, rank() OVER w AS rank\n",
    "FROM\n",
    "    pop_2009\n",
    "WINDOW w AS (PARTITION BY year ORDER BY popularity DESC)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to query.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query.hql -a\n",
    "\n",
    "SELECT\n",
    "    rank_2016.tag, rank_2016.rank, rank_2009.rank, rank_2016.popularity, rank_2009.popularity\n",
    "FROM\n",
    "    rank_2016\n",
    "LEFT JOIN \n",
    "    rank_2009\n",
    "ON\n",
    "    rank_2016.tag = rank_2009.tag\n",
    "ORDER BY\n",
    "    rank_2016.rank\n",
    "LIMIT 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.202 seconds\n",
      "OK\n",
      "Time taken: 0.115 seconds\n",
      "Query ID = jovyan_20180207141616_d7c5e124-c860-458c-b5d3-7c175130c1db\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0047, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0047/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0047\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:16:34,914 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:16:44,799 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.57 sec\n",
      "2018-02-07 14:16:54,669 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 14.27 sec\n",
      "MapReduce Total cumulative CPU time: 14 seconds 270 msec\n",
      "Ended Job = job_1518008069663_0047\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0048, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0048/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0048\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:17:12,701 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:17:21,337 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.88 sec\n",
      "2018-02-07 14:17:30,017 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 8.39 sec\n",
      "MapReduce Total cumulative CPU time: 8 seconds 390 msec\n",
      "Ended Job = job_1518008069663_0048\n",
      "Moving data to: hdfs://localhost:9000/user/jovyan/precreate/pop_2016\n",
      "Table stackoverflow_.pop_2016 stats: [numFiles=1, numRows=9548, totalSize=176212, rawDataSize=166664]\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 14.27 sec   HDFS Read: 835302 HDFS Write: 331434 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 8.39 sec   HDFS Read: 335818 HDFS Write: 176297 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 22 seconds 660 msec\n",
      "OK\n",
      "Time taken: 76.656 seconds\n",
      "OK\n",
      "Time taken: 0.019 seconds\n",
      "Query ID = jovyan_20180207141717_4ec4d2db-e12d-4459-b6bf-1e6ff28b737d\n",
      "Total jobs = 2\n",
      "Launching Job 1 out of 2\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0049, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0049/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0049\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:17:49,365 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:17:58,029 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 6.63 sec\n",
      "2018-02-07 14:18:07,679 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 11.32 sec\n",
      "MapReduce Total cumulative CPU time: 11 seconds 320 msec\n",
      "Ended Job = job_1518008069663_0049\n",
      "Launching Job 2 out of 2\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0050, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0050/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0050\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:18:25,143 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:18:33,709 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 3.17 sec\n",
      "2018-02-07 14:18:43,277 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 8.08 sec\n",
      "MapReduce Total cumulative CPU time: 8 seconds 80 msec\n",
      "Ended Job = job_1518008069663_0050\n",
      "Moving data to: hdfs://localhost:9000/user/jovyan/precreate/pop_2009\n",
      "Table stackoverflow_.pop_2009 stats: [numFiles=1, numRows=2369, totalSize=41196, rawDataSize=38827]\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 11.32 sec   HDFS Read: 145386 HDFS Write: 79828 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 8.08 sec   HDFS Read: 84212 HDFS Write: 41280 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 19 seconds 400 msec\n",
      "OK\n",
      "Time taken: 70.364 seconds\n",
      "OK\n",
      "Time taken: 0.018 seconds\n",
      "Query ID = jovyan_20180207141818_243d5f35-e209-4f5f-9c1d-4f9bc4d0ed55\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0051, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0051/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0051\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:19:01,571 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:19:10,399 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.59 sec\n",
      "2018-02-07 14:19:20,049 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.47 sec\n",
      "MapReduce Total cumulative CPU time: 10 seconds 470 msec\n",
      "Ended Job = job_1518008069663_0051\n",
      "Moving data to: hdfs://localhost:9000/user/jovyan/precreate/rank_2016\n",
      "Table stackoverflow_.rank_2016 stats: [numFiles=1, numRows=9548, totalSize=175102, rawDataSize=165554]\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 10.47 sec   HDFS Read: 183674 HDFS Write: 175188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 470 msec\n",
      "OK\n",
      "Time taken: 37.774 seconds\n",
      "OK\n",
      "Time taken: 0.014 seconds\n",
      "Query ID = jovyan_20180207141919_26bfaa44-6b1e-4aad-9d03-dc1b0706da76\n",
      "Total jobs = 1\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0052, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0052/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0052\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:19:38,190 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:19:46,861 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.32 sec\n",
      "2018-02-07 14:19:59,937 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 10.33 sec\n",
      "MapReduce Total cumulative CPU time: 10 seconds 330 msec\n",
      "Ended Job = job_1518008069663_0052\n",
      "Moving data to: hdfs://localhost:9000/user/jovyan/precreate/rank_2009\n",
      "Table stackoverflow_.rank_2009 stats: [numFiles=1, numRows=2369, totalSize=38713, rawDataSize=36344]\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 10.33 sec   HDFS Read: 48671 HDFS Write: 38798 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 10 seconds 330 msec\n",
      "OK\n",
      "Time taken: 40.012 seconds\n",
      "Query ID = jovyan_20180207142020_2caf6ccd-b71c-498c-b2f6-d821ede7fda7\n",
      "Total jobs = 1\n",
      "Execution log at: /tmp/jovyan/jovyan_20180207142020_2caf6ccd-b71c-498c-b2f6-d821ede7fda7.log\n",
      "2018-02-07 02:20:12\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-02-07 02:20:14\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/5794adad-b9b0-49ba-b3c7-618b502c9fe6/hive_2018-02-07_14-20-02_593_6796880751317025805-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile01--.hashtable\n",
      "2018-02-07 02:20:15\tUploaded 1 File to: file:/tmp/jovyan/5794adad-b9b0-49ba-b3c7-618b502c9fe6/hive_2018-02-07_14-20-02_593_6796880751317025805-1/-local-10004/HashTable-Stage-2/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2018-02-07 02:20:15\tEnd of local task; Time Taken: 2.771 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 1 out of 1\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0053, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0053/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0053\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:20:39,227 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:20:49,544 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.58 sec\n",
      "2018-02-07 14:21:01,591 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 9.68 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 680 msec\n",
      "Ended Job = job_1518008069663_0053\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 9.68 sec   HDFS Read: 186119 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 9 seconds 680 msec\n",
      "OK\n",
      "Time taken: 61.267 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hive -f query.hql 2> out.log\n",
    "cat out.log >&2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplify into 1 query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting query_2.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile query_2.hql\n",
    "\n",
    "USE stackoverflow_;\n",
    "\n",
    "DROP TABLE IF EXISTS pop_2016;\n",
    "DROP TABLE IF EXISTS pop_2009;\n",
    "DROP TABLE IF EXISTS rank_2016;\n",
    "DROP TABLE IF EXISTS rank_2009;\n",
    "\n",
    "\n",
    "SELECT\n",
    "    rank_2016.tag, rank_2016.rank, rank_2009.rank, rank_2016.popularity, rank_2009.popularity\n",
    "FROM (\n",
    "    SELECT\n",
    "        tag, popularity, rank() OVER w AS rank\n",
    "    FROM (\n",
    "        SELECT\n",
    "            year, tag, count(tag) AS popularity\n",
    "        FROM\n",
    "            posts\n",
    "        LATERAL VIEW\n",
    "            explode(tags) posts AS tag\n",
    "        WHERE\n",
    "            year = 2016 AND\n",
    "            post_type_id=1\n",
    "        GROUP BY\n",
    "            year, tag\n",
    "        ORDER BY\n",
    "            popularity DESC\n",
    "    ) AS pop_2016\n",
    "    WINDOW w AS (PARTITION BY year ORDER BY popularity DESC)\n",
    ") AS rank_2016\n",
    "LEFT JOIN (\n",
    "    SELECT\n",
    "        tag, popularity, rank() OVER w AS rank\n",
    "    FROM (\n",
    "        SELECT\n",
    "            year, tag, count(tag) AS popularity\n",
    "        FROM\n",
    "            posts\n",
    "        LATERAL VIEW\n",
    "            explode(tags) posts AS tag\n",
    "        WHERE\n",
    "            year = 2009 AND\n",
    "            post_type_id=1\n",
    "        GROUP BY\n",
    "            year, tag\n",
    "        ORDER BY\n",
    "            popularity DESC\n",
    "    ) AS pop_2009\n",
    "    WINDOW w AS (PARTITION BY year ORDER BY popularity DESC)\n",
    ") AS rank_2009\n",
    "ON\n",
    "    rank_2016.tag = rank_2009.tag\n",
    "ORDER BY\n",
    "    rank_2016.rank\n",
    "LIMIT 10\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "OK\n",
      "Time taken: 1.18 seconds\n",
      "OK\n",
      "Time taken: 1.758 seconds\n",
      "OK\n",
      "Time taken: 0.204 seconds\n",
      "OK\n",
      "Time taken: 0.201 seconds\n",
      "OK\n",
      "Time taken: 0.224 seconds\n",
      "Query ID = jovyan_20180207142121_d5d4c6a4-a145-4c88-a78c-54c6e32e95cf\n",
      "Total jobs = 9\n",
      "Launching Job 1 out of 9\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0054, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0054/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0054\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:21:39,333 Stage-1 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:21:49,517 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 7.25 sec\n",
      "2018-02-07 14:21:59,287 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 12.32 sec\n",
      "MapReduce Total cumulative CPU time: 12 seconds 320 msec\n",
      "Ended Job = job_1518008069663_0054\n",
      "Launching Job 2 out of 9\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0055, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0055/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0055\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:22:16,960 Stage-6 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:22:29,178 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 6.05 sec\n",
      "2018-02-07 14:22:41,342 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 12.35 sec\n",
      "MapReduce Total cumulative CPU time: 12 seconds 350 msec\n",
      "Ended Job = job_1518008069663_0055\n",
      "Launching Job 3 out of 9\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0056, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0056/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0056\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:23:03,682 Stage-2 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:23:15,281 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 5.3 sec\n",
      "2018-02-07 14:23:25,270 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 9.78 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 780 msec\n",
      "Ended Job = job_1518008069663_0056\n",
      "Launching Job 4 out of 9\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0057, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0057/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0057\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:23:46,034 Stage-7 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:23:58,453 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 3.73 sec\n",
      "2018-02-07 14:24:08,028 Stage-7 map = 100%,  reduce = 100%, Cumulative CPU 7.53 sec\n",
      "MapReduce Total cumulative CPU time: 7 seconds 530 msec\n",
      "Ended Job = job_1518008069663_0057\n",
      "Launching Job 5 out of 9\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0058, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0058/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0058\n",
      "Hadoop job information for Stage-3: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:24:26,189 Stage-3 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:24:35,968 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 4.84 sec\n",
      "2018-02-07 14:24:46,666 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 12.14 sec\n",
      "MapReduce Total cumulative CPU time: 12 seconds 140 msec\n",
      "Ended Job = job_1518008069663_0058\n",
      "Launching Job 6 out of 9\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0059, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0059/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0059\n",
      "Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:25:08,860 Stage-8 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:25:19,400 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 4.26 sec\n",
      "2018-02-07 14:25:29,075 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 9.99 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 990 msec\n",
      "Ended Job = job_1518008069663_0059\n",
      "Stage-11 is selected by condition resolver.\n",
      "Stage-4 is filtered out by condition resolver.\n",
      "Execution log at: /tmp/jovyan/jovyan_20180207142121_d5d4c6a4-a145-4c88-a78c-54c6e32e95cf.log\n",
      "2018-02-07 02:25:38\tStarting to launch local task to process map join;\tmaximum memory = 477626368\n",
      "2018-02-07 02:25:39\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/b002d87b-5a2d-4aef-a374-4e945325a611/hive_2018-02-07_14-21-22_119_4230200541955153884-1/-local-10010/HashTable-Stage-9/MapJoin-mapfile01--.hashtable\n",
      "2018-02-07 02:25:39\tUploaded 1 File to: file:/tmp/jovyan/b002d87b-5a2d-4aef-a374-4e945325a611/hive_2018-02-07_14-21-22_119_4230200541955153884-1/-local-10010/HashTable-Stage-9/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2018-02-07 02:25:39\tEnd of local task; Time Taken: 1.766 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 8 out of 9\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1518008069663_0060, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0060/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0060\n",
      "Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 0\n",
      "2018-02-07 14:25:56,120 Stage-9 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:26:06,341 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 5.44 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 440 msec\n",
      "Ended Job = job_1518008069663_0060\n",
      "Launching Job 9 out of 9\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1518008069663_0061, Tracking URL = http://b5f1542b981e:8088/proxy/application_1518008069663_0061/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1518008069663_0061\n",
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2018-02-07 14:26:23,959 Stage-5 map = 0%,  reduce = 0%\n",
      "2018-02-07 14:26:32,508 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 3.93 sec\n",
      "2018-02-07 14:26:42,239 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 9.27 sec\n",
      "MapReduce Total cumulative CPU time: 9 seconds 270 msec\n",
      "Ended Job = job_1518008069663_0061\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 12.32 sec   HDFS Read: 835387 HDFS Write: 331434 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 12.35 sec   HDFS Read: 145489 HDFS Write: 79828 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 9.78 sec   HDFS Read: 335439 HDFS Write: 331434 SUCCESS\n",
      "Stage-Stage-7: Map: 1  Reduce: 1   Cumulative CPU: 7.53 sec   HDFS Read: 83833 HDFS Write: 79828 SUCCESS\n",
      "Stage-Stage-3: Map: 1  Reduce: 1   Cumulative CPU: 12.14 sec   HDFS Read: 337185 HDFS Write: 311766 SUCCESS\n",
      "Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 9.99 sec   HDFS Read: 85579 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-9: Map: 1   Cumulative CPU: 5.44 sec   HDFS Read: 316332 HDFS Write: 317868 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 9.27 sec   HDFS Read: 323118 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 1 minutes 18 seconds 820 msec\n",
      "OK\n",
      "Time taken: 321.244 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hive -f query_2.hql 2> out.log\n",
    "cat out.log >&2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
